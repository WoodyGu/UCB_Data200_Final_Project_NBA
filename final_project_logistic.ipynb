{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 200 Final Project (Peng Gu, Xi Chen, Kewei Sui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style = \"whitegrid\", \n",
    "        color_codes = True,\n",
    "        font_scale = 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model as lm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import tree\n",
    "# ignore the warning you might get from importing ensemble from sklearn\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all datasets\n",
    "df_player = pd.read_csv('dataset/2012-18_playerBoxScore.csv')\n",
    "df_all_nba_team = pd.read_csv('dataset/all_nba_team_2012_2017.csv')\n",
    "df_player['gmDate'] = pd.to_datetime(df_player['gmDate'], format='%Y-%m-%d')\n",
    "df_player['playBDate'] = pd.to_datetime(df_player['playBDate'], format='%Y-%m-%d')\n",
    "\n",
    "# df_all_nba_team.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set the number of NBA season based on the game date and the start date of each season in 2012-18\n",
    "start_dates = ['2012-10-30', '2013-10-29', '2014-10-28', '2015-10-27','2016-10-25','2017-10-17','2018-10-16']\n",
    "for i in range(len(start_dates)):\n",
    "    start_dates[i] = datetime.datetime.strptime(start_dates[i],'%Y-%m-%d')\n",
    "\n",
    "def setSeasons(gm_date):\n",
    "    for i in range(len(start_dates) - 1):\n",
    "        if gm_date >= start_dates[i] and gm_date < start_dates[i + 1]:\n",
    "            return start_dates[i].year\n",
    "\n",
    "df_player[\"seasYear\"] = df_player['gmDate'].apply(lambda x:setSeasons(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We find out in the dataset \"2012-18_playerBoxScore.csv\", and there is no data for the pre or post season\n",
    "# Thus, we will only evaluate players based on their performances in the regular season\n",
    "df_player = df_player[df_player.seasTyp != 'Pre']\n",
    "df_player = df_player[df_player.seasTyp != 'Post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_player.loc[df_player['playMin'] != 0, 'playFIC40'] = ((df_player['playPTS'] + df_player['playORB'] + 0.75 * df_player['playDRB'] + df_player['playAST'] + df_player['playSTL'] + df_player['playBLK'] - 0.75 * df_player['playFGA'] - 0.375 * df_player['playFTA'] - df_player['playTO'] - 0.5 * df_player['playPF']) * 40) / df_player['playMin']\n",
    "df_player.loc[df_player['playMin'] == 0, 'playFIC40'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_player[\"gameScore\"] = df_player[\"playPTS\"] + 0.4 * df_player[\"playFGM\"] - 0.7 * df_player[\"playFGA\"] - 0.4 * (df_player[\"playFTA\"] - df_player[\"playFTM\"]) + 0.7 * df_player[\"playORB\"] + 0.3 * df_player[\"playDRB\"] + df_player[\"playSTL\"] + 0.7 * df_player[\"playAST\"] + 0.7 * df_player[\"playBLK\"] - 0.4 * df_player[\"playPF\"] - df_player[\"playTO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_player = df_player.replace([np.inf, -np.inf], np.nan)\n",
    "# df_player.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning\n",
    "df_player['offLNm3'] = df_player['offLNm3'].fillna(df_player['offLNm2'])\n",
    "df_player['offFNm3'] = df_player['offFNm3'].fillna(df_player['offFNm2'])\n",
    "# df_player.loc[df_player['playDispNm'] == 'Goran DragiÄ‡']['playDispNm'] = 'Goran Dragic'\n",
    "df_player['playDispNm'] = df_player['playDispNm'].replace({'Goran DragiÄ‡':'Goran Dragic'})\n",
    "# df_player.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning\n",
    "df_player = df_player.drop(columns=['teamDiv', 'teamDayOff', 'offLNm1', 'offFNm1', 'offLNm2', 'offFNm2', \\\n",
    "      'offLNm3', 'offFNm3', 'opptDiv', 'opptDayOff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_player[\"playPos\"] = df_player[\"playPos\"].replace({'PG':'G', 'SG':'G', 'SF':'F', 'PF':'F'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_starter_bench = pd.pivot_table(data=df_player, index=['playDispNm','seasYear'],columns='playStat',values='teamAbbr',aggfunc='count')\n",
    "player_starter_bench = player_starter_bench.fillna(0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "allnba_starter_bench = player_starter_bench.merge(right=df_all_nba_team, how='inner', left_on=['playDispNm', 'seasYear'], right_on=['name','year'])\n",
    "allnba_starter_bench.drop(columns=['name', 'year'], inplace=True)\n",
    "allnba_starter_bench.sort_values(by=['seasYear', 'sub_team'], inplace=True, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_player_starter_vs_FIC40 = df_player[['playDispNm', 'playFIC40', 'seasYear']].groupby([\"playDispNm\", \"seasYear\"]).mean()\n",
    "# df_player_starter_vs_FIC40 = df_player_starter_vs_FIC40.merge(player_starter_bench, on=['playDispNm', 'seasYear'], how='inner')\n",
    "\n",
    "# #df_2012 = df[df[\"seasYear\"] == 2012]\n",
    "# #allnba_2012 = allnba_regular_starter_bench[allnba_regular_starter_bench[\"seasYear\"] == 2012]\n",
    "\n",
    "# plt.figure(figsize=(15,8))\n",
    "# plt.ylim(-10, 30)\n",
    "# plt.title(\"Relationship between starter number and floor impact per 40 minutes \")\n",
    "# plt.xlabel(\"player's starter number\")\n",
    "# plt.ylabel(\"player's floor impact per 40 minutes\")\n",
    "\n",
    "# df_allnba_starter_vs_FIC40 = df_player_starter_vs_FIC40.merge(allnba_starter_bench, on=[\"playDispNm\", \"seasYear\", \"Bench\", \"Starter\"])\n",
    "\n",
    "# plt.scatter(df_player_starter_vs_FIC40['Starter'], df_player_starter_vs_FIC40[\"playFIC40\"], color='blue', label=\"all players\")\n",
    "# plt.scatter(df_allnba_starter_vs_FIC40['Starter'], df_allnba_starter_vs_FIC40['playFIC40'], color='red', label=\"players in all nba teams\")\n",
    "# plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for Pre-Processing data to fit the model\n",
    "# display(df_player)\n",
    "# df_model = df_player[['playDispNm', 'teamLoc','teamRslt', 'teamAbbr', 'teamConf','playStat','playMin','playPos','playHeight','playWeight','playBDate',]]\n",
    "# join \n",
    "df_all_nba_team['is_allnba'] = 1\n",
    "df_player = df_player.merge(right=df_all_nba_team, how='left', left_on=['playDispNm','seasYear'], right_on=['name','year'])\n",
    "df_player = df_player.drop(columns=['name','year','position','team'])\n",
    "df_player['sub_team'].fillna(0, inplace=True)\n",
    "df_player['is_allnba'].fillna(0,inplace=True)\n",
    "# df_player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for calculate how long this person has lived until the game\n",
    "df_player['age'] = df_player['gmDate'] - df_player['playBDate']\n",
    "df_player['age'] = df_player['age'].dt.days\n",
    "# df_player.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_player = df_player\n",
    "new_df_player['teamRslt'] = new_df_player['teamRslt'].replace(['Win', 'Loss'], [1, 0])\n",
    "playStat_ohe = pd.get_dummies(new_df_player['playStat'])\n",
    "new_df_player['sub_team'] = new_df_player['sub_team'].replace([1, 2, 3, 0], ['first_team', 'second_team', 'thrid_team', 'isnt_allnba'])\n",
    "sub_team_ohe = pd.get_dummies(new_df_player['sub_team'])\n",
    "new_df_player['playPos'] = new_df_player['playPos'].replace(['F', 'C', 'G'], ['Forward', 'Center', 'Guard'])\n",
    "new_df_player = pd.concat([new_df_player, playStat_ohe, sub_team_ohe], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate df_player into 6 small data frames\n",
    "df_player_collection = {}\n",
    "for i in range(2012, 2018):\n",
    "    df_player_collection[i] = new_df_player[new_df_player[\"seasYear\"] == i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate player average performance in each year\n",
    "def regularizeDataPerYear(df):\n",
    "    df_mostPlayPos = df.groupby('playDispNm')['playPos'].apply(lambda x: x.mode().iat[0])\n",
    "    df_sumStarter = df.groupby('playDispNm')['Starter'].agg('sum')\n",
    "    df_sumBench = df.groupby('playDispNm')['Bench'].agg('sum')\n",
    "    #df_mostTeamAbbr = df_player_2012.groupby('playDispNm')['teamAbbr'].agg(pd.Series.mode)\n",
    "    #df_mostTeamConf = df_player_2012.groupby('playDispNm')['teamConf'].agg(pd.Series.mode)\n",
    "\n",
    "    df = df.groupby('playDispNm').agg('mean')\n",
    "    df = pd.concat([df, df_mostPlayPos], axis=1)\n",
    "    df['Starter'] = df_sumStarter\n",
    "    df['Bench'] = df_sumBench\n",
    "\n",
    "    playPos_ohe = pd.get_dummies(df['playPos'])\n",
    "    df = pd.concat([df, playPos_ohe], axis=1)\n",
    "\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(columns=['playDispNm', 'playPos', 'seasYear', 'playFIC40'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularize data in each year\n",
    "for i in range(2012, 2018):\n",
    "    df_player_collection[i] = regularizeDataPerYear(df_player_collection[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticModel(df):\n",
    "    # Train Test split (Unstratified)\n",
    "    '''\n",
    "    np.random.seed(47)\n",
    "    X = df.drop(columns=['is_allnba', 'first_team', 'second_team', 'thrid_team', 'isnt_allnba'])\n",
    "\n",
    "    # Choose different Y\n",
    "    Y = pd.Series(df['is_allnba'])\n",
    "    #Y = pd.Series(df_model['first_team'])\n",
    "    #Y = pd.Series(df_model['second_team'])\n",
    "    #Y = pd.Series(df_model['thrid_team'])\n",
    "    #Y = pd.Series(df_model['isnt_allnba'])\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "    '''\n",
    "\n",
    "    # Train test split (Stratified)\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=47)\n",
    "\n",
    "    # Stratify the data by category and store value into train and test sets\n",
    "    for train_index, test_index in split.split(df, df['is_allnba']):\n",
    "        train_set = df.loc[train_index]\n",
    "        test_set = df.loc[test_index]\n",
    "\n",
    "    X_train = train_set.drop(columns=['is_allnba', 'first_team', 'second_team', 'thrid_team', 'isnt_allnba'])\n",
    "    X_test = test_set.drop(columns=['is_allnba', 'first_team', 'second_team', 'thrid_team', 'isnt_allnba'])\n",
    "    Y_train = pd.Series(train_set['is_allnba'])\n",
    "    Y_test = pd.Series(test_set['is_allnba'])\n",
    "\n",
    "    '''\n",
    "    # Logistic regression model\n",
    "    logistic_model = lm.LogisticRegressionCV(fit_intercept=True, cv=10, penalty='l1', solver='saga', max_iter=10000)\n",
    "    #logistic_model = lm.RidgeCV(fit_intercept=True, cv=10)\n",
    "    logistic_model.fit(X_train, Y_train)\n",
    "    Y_predict = logistic_model.predict(X_test)\n",
    "    Y_fitted = logistic_model.predict(X_train)\n",
    "    '''\n",
    "\n",
    "    # Random forest model\n",
    "    random_forest_model = ensemble.RandomForestClassifier(n_estimators=150)\n",
    "    random_forest_model.fit(X_train, Y_train)\n",
    "    Y_predict = random_forest_model.predict(X_test)\n",
    "    Y_fitted = random_forest_model.predict(X_train)\n",
    "\n",
    "    # Calculate precision, recall, false-alarm, F-Score and training & testing accuracy\n",
    "    training_TP = 0\n",
    "    training_FP = 0\n",
    "    training_FN = 0\n",
    "    training_TN = 0\n",
    "\n",
    "    testing_TP = 0\n",
    "    testing_FP = 0\n",
    "    testing_FN = 0\n",
    "    testing_TN = 0\n",
    "\n",
    "    Y_train_array = Y_train.to_numpy()\n",
    "    Y_test_array = Y_test.to_numpy()\n",
    "\n",
    "    for i in range(len(X_train)):\n",
    "        if Y_fitted[i] == 1 and Y_train_array[i] == 1:\n",
    "            training_TP += 1\n",
    "        elif Y_fitted[i] == 1 and Y_train_array[i] == 0:\n",
    "            training_FP += 1\n",
    "        elif Y_fitted[i] == 0 and Y_train_array[i] == 1:\n",
    "            training_FN += 1\n",
    "        elif Y_fitted[i] == 0 and Y_train_array[i] == 0:\n",
    "            training_TN += 1\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        if Y_predict[i] == 1 and Y_test_array[i] == 1:\n",
    "            testing_TP += 1\n",
    "        elif Y_predict[i] == 1 and Y_test_array[i] == 0:\n",
    "            testing_FP += 1\n",
    "        elif Y_predict[i] == 0 and Y_test_array[i] == 1:\n",
    "            testing_FN += 1\n",
    "        elif Y_predict[i] == 0 and Y_test_array[i] == 0:\n",
    "            testing_TN += 1\n",
    "\n",
    "    training_precision = 0\n",
    "    training_recall = 0\n",
    "    training_far = 0\n",
    "    training_f_measure = 0\n",
    "\n",
    "    if training_TP is not 0:\n",
    "        training_precision = training_TP / (training_TP + training_FP)\n",
    "        training_recall = training_TP / (training_TP + training_FN)\n",
    "    if training_FP is not 0:\n",
    "        training_far = training_FP / (training_FP + training_TN)\n",
    "    if training_precision is not 0:\n",
    "        training_f_measure = 2.0 * training_precision * training_recall / (training_precision + training_recall)\n",
    "\n",
    "    testing_precision = 0\n",
    "    testing_recall = 0\n",
    "    testing_far = 0\n",
    "    testing_f_measure = 0\n",
    "\n",
    "    if testing_TP is not 0:\n",
    "        testing_precision = testing_TP / (testing_TP + testing_FP)\n",
    "        testing_recall = testing_TP / (testing_TP + testing_FN)\n",
    "    if testing_FP is not 0:\n",
    "        testing_far = testing_FP / (testing_FP + testing_TN)\n",
    "    if testing_precision is not 0:\n",
    "        testing_f_measure = 2.0 * testing_precision * testing_recall / (testing_precision + testing_recall)\n",
    "\n",
    "    training_accuracy = sum(Y_train == Y_fitted) / len(Y_fitted)\n",
    "    testing_accuracy = sum(Y_test == Y_predict) / len(Y_test)\n",
    "\n",
    "    '''\n",
    "    print(\"Training Accuracy:\", training_accuracy)\n",
    "    print(\"Testing Accuracy:\", testing_accuracy)\n",
    "\n",
    "    print(\"Training Precision:\", training_precision)\n",
    "    print(\"Training Recall:\", training_recall)\n",
    "    print(\"Training False-alarm:\", training_far)\n",
    "    print(\"Training F-Measure:\", training_f_measure)\n",
    "\n",
    "    print(\"Testing Precision:\", testing_precision)\n",
    "    print(\"Testing Recall:\", testing_recall)\n",
    "    print(\"Testing False-alarm:\", testing_far)\n",
    "    print(\"Testing F-Measure:\", testing_f_measure)\n",
    "    '''\n",
    "\n",
    "    return [training_accuracy, training_precision, training_recall, training_far, training_f_measure, testing_accuracy, testing_precision, testing_recall, testing_far, testing_f_measure]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Average Training Accuracy: 1.0 Std: 0.0\nAverage Training Precision: 1.0 Std: 0.0\nAverage Training Recall: 1.0 Std: 0.0\nAverage Training False-alarm: 0.0 Std: 0.0\nAverage Training F-Measure: 1.0 Std: 0.0\nAverage Testing Accuracy: 0.9845671166929354 Std: 0.009709785822624304\nAverage Testing Precision: 0.8194444444444443 Std: 0.19493984510580833\nAverage Testing Recall: 0.6666666666666666 Std: 0.2721655269759087\nAverage Testing False-alarm: 0.005282611771363893 Std: 0.005283538093418822\nAverage Testing F-Measure: 0.703968253968254 Std: 0.20644228669888676\n"
    }
   ],
   "source": [
    "totalPerformance = [[] for _ in range(10)]\n",
    "\n",
    "for i in range(2012, 2018):\n",
    "    result = LogisticModel(df_player_collection[i])\n",
    "    for i in range(10):\n",
    "        totalPerformance[i].append(result[i])\n",
    "\n",
    "Text = [\"Average Training Accuracy:\", \"Average Training Precision:\", \"Average Training Recall:\", \"Average Training False-alarm:\", \"Average Training F-Measure:\", \"Average Testing Accuracy:\", \"Average Testing Precision:\", \"Average Testing Recall:\", \"Average Testing False-alarm:\", \"Average Testing F-Measure:\"]\n",
    "\n",
    "for i in range(10):\n",
    "    print(Text[i], np.mean(totalPerformance[i]), \"Std:\", np.std(totalPerformance[i]))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37432bitvenvvenv44deada86dba45d7a8ff0578f91cb8fa",
   "display_name": "Python 3.7.4 32-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}